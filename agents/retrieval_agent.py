# agents/retrieval_agent.py

from typing import List, Dict, Any, Optional
from agents.base_agent import Agent
from agents.mcp_messages import MCPMessage, create_mcp_message, \
                                 IngestionCompletePayload, QueryRequestPayload, \
                                 RetrievalResultPayload, ErrorPayload
from utils.embeddings import EmbeddingModel
from utils.vector_store import VectorStore
import os
import shutil
import numpy as np

class RetrievalAgent(Agent):
    """
    The RetrievalAgent is responsible for:
    1. Receiving processed chunks from the IngestionAgent.
    2. Embedding these chunks and adding them to a persistent vector store (FAISS).
    3. Receiving user queries from the CoordinatorAgent.
    4. Embedding the queries and performing similarity search against the vector store.
    5. Sending the most relevant retrieved chunks to the LLMResponseAgent.
    6. Managing the persistence (loading/saving/clearing) of the vector store.
    """
    def __init__(self, message_broker, embedding_dim: int = 768, vector_store_dir: str = "vector_store_data"):
        """
        Initializes the RetrievalAgent.

        Args:
            message_broker (Callable[[MCPMessage], None]): The method to send messages to the Coordinator.
            embedding_dim (int): The dimension of the embeddings generated by the model.
            vector_store_dir (str): The directory path where the vector store data should be saved/loaded.
        """
        super().__init__("RetrievalAgent", message_broker)
        
        # Initialize the embedding model
        try:
            self.embedding_model = EmbeddingModel(model_name="models/text-embedding-004")
        except Exception as e:
            print(f"[{self.name}] Failed to initialize embedding model: {e}")
            raise
            
        self.vector_store_dir = vector_store_dir
        
        # Load an existing vector store or create a new one
        self.vector_store = self._load_or_create_vector_store(embedding_dim)
        print(f"[{self.name}] Initialized. Vector store contains {len(self.vector_store.get_all_chunks())} vectors.")

    def _load_or_create_vector_store(self, embedding_dim: int) -> VectorStore:
        """
        Attempts to load an existing vector store from the specified directory.
        If loading fails (e.g., file not found, corrupted), or if the directory
        doesn't exist, a new empty VectorStore is created.

        Args:
            embedding_dim (int): The dimension required for the vector store if a new one is created.

        Returns:
            VectorStore: An initialized VectorStore instance.
        """
        # Ensure the persistence directory exists for saving new stores
        os.makedirs(self.vector_store_dir, exist_ok=True)

        try:
            print(f"[{self.name}] Attempting to load vector store from {self.vector_store_dir}...")
            vector_store = VectorStore.load_local(self.vector_store_dir, self.embedding_model)
            print(f"[{self.name}] Successfully loaded vector store with {len(vector_store.get_all_chunks())} chunks.")
            return vector_store
        except Exception as e:
            print(f"[{self.name}] Could not load vector store from {self.vector_store_dir}: {e}. Creating a new one.")
            return VectorStore(embedding_dim, self.embedding_model)

    def _save_vector_store(self):
        """
        Saves the current state of the vector store (FAISS index and chunk metadata) to disk.
        This ensures persistence across application restarts.
        """
        if self.vector_store:
            try:
                self.vector_store.save_local(self.vector_store_dir)
                print(f"[{self.name}] Vector store saved to {self.vector_store_dir}.")
            except Exception as e:
                print(f"[{self.name}] Error saving vector store to {self.vector_store_dir}: {e}")

    def process_message(self, message: MCPMessage):
        """
        Processes incoming MCP messages.
        Handles 'INGESTION_COMPLETE' messages to add chunks to the vector store
        and 'QUERY_REQUEST' messages to perform retrieval.

        Args:
            message (MCPMessage): The incoming message.
        """
        trace_id = message["trace_id"]
        msg_type = message["type"]
        sender = message["sender"]

        print(f"[{self.name}] Received message of type: {msg_type} (Trace ID: {trace_id})")

        if msg_type == "INGESTION_COMPLETE":
            self._handle_ingestion_complete(message)
        elif msg_type == "QUERY_REQUEST":
            self._handle_query_request(message)
        else:
            print(f"[{self.name}] Unhandled message type received: {msg_type} (Trace ID: {trace_id})")

    def _handle_ingestion_complete(self, message: MCPMessage):
        """Handle INGESTION_COMPLETE messages."""
        trace_id = message["trace_id"]
        sender = message["sender"]
        
        try:
            payload: IngestionCompletePayload = message["payload"]
            chunks = payload.get("chunks", [])
            
            if not chunks:
                print(f"[{self.name}] No chunks received for ingestion in INGESTION_COMPLETE message (Trace ID: {trace_id}).")
                return

            print(f"[{self.name}] Adding {len(chunks)} chunks to vector store...")
            
            # Filter out chunks with empty content before processing
            valid_chunks = [chunk for chunk in chunks if chunk.get("content", "").strip()]
            if len(valid_chunks) != len(chunks):
                print(f"[{self.name}] Filtered out {len(chunks) - len(valid_chunks)} chunks with empty content.")
            
            if not valid_chunks:
                print(f"[{self.name}] No valid chunks to add after filtering.")
                return
            
            # Add chunks to the vector store
            chunk_ids = self.vector_store.add_chunks(valid_chunks)
            
            print(f"[{self.name}] Added {len(chunk_ids)} embeddings to vector store.")
            print(f"[{self.name}] Vector store now contains {len(self.vector_store.get_all_chunks())} vectors.")
            
            # Save the updated vector store to disk
            self._save_vector_store()

        except Exception as e:
            print(f"[{self.name}] Error processing INGESTION_COMPLETE: {e}")
            error_payload: ErrorPayload = {"message": f"Error during chunk ingestion into vector store: {e}"}
            self.send_message(
                receiver=sender,
                msg_type="ERROR",
                payload=error_payload,
                trace_id=trace_id
            )

    def _handle_query_request(self, message: MCPMessage):
        """Handle QUERY_REQUEST messages."""
        trace_id = message["trace_id"]
        sender = message["sender"]
        
        try:
            payload: QueryRequestPayload = message["payload"]
            query = payload.get("query")
            conversation_history = payload.get("conversation_history", [])

            if not query or not query.strip():
                print(f"[{self.name}] No valid query in QUERY_REQUEST message. Cannot perform retrieval (Trace ID: {trace_id}).")
                error_payload: ErrorPayload = {"message": "Missing or empty query in query request payload."}
                self.send_message(
                    receiver=sender,
                    msg_type="ERROR",
                    payload=error_payload,
                    trace_id=trace_id
                )
                return

            print(f"[{self.name}] Embedding query: '{query[:50]}...'")
            
            # Embed the user's query
            query_embedding = self.embedding_model.embed_query(query.strip())

            # Check if query embedding is valid
            if not query_embedding or len(query_embedding) == 0:
                error_msg = "Failed to generate embedding for the query (embedding is empty)."
                print(f"[{self.name}] {error_msg}")
                error_payload: ErrorPayload = {"message": error_msg}
                self.send_message(
                    receiver=sender,
                    msg_type="ERROR",
                    payload=error_payload,
                    trace_id=trace_id
                )
                return

            print(f"[{self.name}] Successfully generated query embedding of dimension: {len(query_embedding)}")
            print(f"[{self.name}] Searching vector store for top 3 relevant chunks...")
            
            # Perform similarity search to get relevant chunks
            relevant_chunks_with_scores = self.vector_store.similarity_search_with_score(query_embedding, k=3)
            
            print(f"[{self.name}] Found {len(relevant_chunks_with_scores)} relevant chunks.")

            # Prepare the payload for the LLMResponseAgent
            retrieval_result_payload: RetrievalResultPayload = {
                "query": query,
                "retrieved_chunks": relevant_chunks_with_scores,
                "conversation_history": conversation_history
            }
            
            # Send the retrieval results to the LLMResponseAgent
            self.send_message(
                receiver="LLMResponseAgent",
                msg_type="RETRIEVAL_RESULT",
                payload=retrieval_result_payload,
                trace_id=trace_id
            )

        except Exception as e:
            print(f"[{self.name}] Error during query retrieval: {e}")
            error_payload: ErrorPayload = {"message": f"Error during retrieval: {e}"}
            self.send_message(
                receiver=sender,
                msg_type="ERROR",
                payload=error_payload,
                trace_id=trace_id
            )


# Standalone test for RetrievalAgent
if __name__ == '__main__':
    from agents.mcp_messages import create_mcp_message, IngestionCompletePayload, QueryRequestPayload
    from unittest.mock import MagicMock, ANY
    import time
    import tempfile
    import shutil

    print("--- Testing RetrievalAgent standalone ---")

    # Use a temporary directory for testing persistence
    temp_vector_store_dir = tempfile.mkdtemp()
    print(f"Using temporary vector store directory: {temp_vector_store_dir}")

    # Mock the message broker
    mock_broker = MagicMock()
    mock_broker.send_message.return_value = None

    try:
        retrieval_agent = RetrievalAgent(mock_broker, vector_store_dir=temp_vector_store_dir)

        # Test 1: Simulate INGESTION_COMPLETE message
        print("\n--- Testing INGESTION_COMPLETE message ---")
        test_chunks_data = [
            {"id": "doc1_p1", "content": "The quick brown fox jumps over the lazy dog.", "metadata": {"source": "test1.txt"}},
            {"id": "doc1_p2", "content": "The dog is lazy and sleeps all day.", "metadata": {"source": "test1.txt"}},
            {"id": "doc2_p1", "content": "Foxes are cunning predators.", "metadata": {"source": "test2.txt"}},
        ]
        
        ingestion_payload: IngestionCompletePayload = {"chunks": test_chunks_data}
        ingestion_message = create_mcp_message(
            sender="IngestionAgent",
            receiver="RetrievalAgent",
            msg_type="INGESTION_COMPLETE",
            payload=ingestion_payload,
            trace_id="ingest_trace_123"
        )
        
        retrieval_agent.process_message(ingestion_message)
        time.sleep(1)

        # Verify chunks were added
        assert len(retrieval_agent.vector_store.get_all_chunks()) == len(test_chunks_data)
        print("✓ Ingestion test passed")

        # Test 2: Simulate QUERY_REQUEST message
        print("\n--- Testing QUERY_REQUEST message ---")
        user_query = "What animal is lazy?"
        conversation_history = []

        query_payload: QueryRequestPayload = {
            "query": user_query,
            "conversation_history": conversation_history
        }
        
        query_message = create_mcp_message(
            sender="CoordinatorAgent",
            receiver="RetrievalAgent",
            msg_type="QUERY_REQUEST",
            payload=query_payload,
            trace_id="query_trace_456"
        )
        
        retrieval_agent.process_message(query_message)
        time.sleep(1)

        # Verify RETRIEVAL_RESULT was sent
        mock_broker.send_message.assert_called_with(
            receiver="LLMResponseAgent",
            msg_type="RETRIEVAL_RESULT",
            payload=ANY,
            trace_id="query_trace_456"
        )
        print("✓ Query retrieval test passed")

        # Test 3: Test persistence
        print("\n--- Testing persistence ---")
        new_retrieval_agent = RetrievalAgent(mock_broker, vector_store_dir=temp_vector_store_dir)
        assert len(new_retrieval_agent.vector_store.get_all_chunks()) == len(test_chunks_data)
        print("✓ Persistence test passed")

    except Exception as e:
        print(f"Test failed: {e}")
        raise
    finally:
        # Clean up
        shutil.rmtree(temp_vector_store_dir)
        print("✓ All RetrievalAgent tests passed!")